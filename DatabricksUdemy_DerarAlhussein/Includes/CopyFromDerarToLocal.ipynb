{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f57d299c-db8c-44e4-8244-62ab7c3dce57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../Includes/Copy-Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a217ecc4-4901-4e9a-9d5d-20e78caa3777",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../StorageUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71f3fcb5-138e-45d9-ba6b-4150953c0c98",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "list_of_folders_objs = dbutils.fs.ls(\"/mnt/demo-datasets/bookstore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aeaa8474-272d-4b3e-82d3-655aad3b5f5d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# print(f'List of folders: {list_of_folders_objs}')\n",
    "#print(type(list_of_folders[0]))\n",
    "\n",
    "list_of_folders = []\n",
    "for folder in list_of_folders_objs:\n",
    "    list_of_folders.append(folder.name)\n",
    "\n",
    "\n",
    "print(list_of_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02dad87e-9586-4566-9521-f094d0069116",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.fs.ls('/mnt/demo-datasets/bookstore/books-cdc/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7a4759c-4dca-43c5-a36f-caab9c4828cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define the source folder in DBFS (use dbfs:/ for listing, and /dbfs/ for actual access)\n",
    "dbfs_folder_path = \"dbfs:/mnt/demo-datasets/bookstore\"  # <-- Use dbfs:/ for listing\n",
    "local_folder_path = \"dbfs:/mnt/azuresa/bookstore\"  # <-- Local base folder\n",
    "\n",
    "# Function to recursively copy files from DBFS to local machine\n",
    "def copy_folder_files(folder_to_copy):\n",
    "    dbfs_files = dbutils.fs.ls(os.path.join(dbfs_folder_path, folder_to_copy))\n",
    "    \n",
    "    # print(f'This is dbfs files {dbfs_files} in {folder_to_copy}')\n",
    "    dbutils.fs.mkdirs(os.path.join(local_folder_path, folder_to_copy))\n",
    "    azure_folder = os.path.join(local_folder_path, folder_to_copy)\n",
    "    for file in dbfs_files:\n",
    "        # Get the DBFS file/folder path\n",
    "        dbfs_file_path = file.path\n",
    "        \n",
    "        # Convert to a valid file system path (use /dbfs/ for reading/writing)\n",
    "        local_file_path = os.path.join(azure_folder, os.path.basename(dbfs_file_path))\n",
    "        \n",
    "        # actual_dbfs_path = dbfs_file_path.replace(\"dbfs:/\", \"/dbfs/\")  # Corrected path\n",
    "        file_content = dbutils.fs.head(dbfs_file_path)\n",
    "        # Write the content to the destination file\n",
    "        dbutils.fs.put(local_file_path, file_content, overwrite=True)\n",
    "\n",
    "        print(f\"Copied {os.path.basename(dbfs_file_path)} to {local_file_path}\")\n",
    "\n",
    "# Start the recursive copying from the top-level DBFS folder\n",
    "for folder_to_copy in list_of_folders:\n",
    "    copy_folder_files(folder_to_copy)\n",
    "\n",
    "\n",
    "print(\"All files and subfolders copied successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41e52006-5d2a-4a47-bec2-b2b10af199de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.fs.ls('dbfs:/mnt/azuresa/bookstore/orders-streaming/')"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "CopyFromDerarToLocal",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
